\newsheet{Day 4: LLL Reduction}{3}{4}

\begin{displayquote}
	``Computational aspects of geometry of numbers have been revolutionized by the 	Lenstra-Lenstra-Lov\'asz lattice reduction algorithm (LLL), which has led to breakthroughs in fields as diverse as computer algebra, cryptology, and algorithmic number theory. After its publication in 1982, LLL was immediately recognized as one of the most important algorithmic achievements of the twentieth century, because of its broad applicability and apparent simplicity.''
\end{displayquote}
\begin{flushright}\small
	$\sim$ Phong Q. Nguyen and Brigitte Vall\'ee (2009)
\end{flushright}

We need a better notion of ``reduced'' bases for dimensions above $2$. For instance, let's use our example from before:

\[\b_1=\begin{pmatrix}
1\\0\\-10^{-6}
\end{pmatrix},\,\b_2=\begin{pmatrix}
1/2 \\ \sqrt{3}/2 \\ 2\cdot 10^{-6}
\end{pmatrix},\,\b_3=\begin{pmatrix}
-1/2 \\ \sqrt{3}/2 \\ -3\cdot 10^{-6}
\end{pmatrix},\,\b_2-\b_1-\b_3=\begin{pmatrix}
0 \\ 0 \\ 6\cdot 10^{-6}
\end{pmatrix}.\]

How could we have predicted the existence of a short vector? One way (discussed yesterday) is Minkowski's Theorem, but this couldn't have prepared us for just how short the shortest vector is. Another approach is to notice that $\b_3$ is \emph{extremely close} to the plane spanned by $\b_1$ and $\b_2$. In other words, the only contribution from $\b_3$ in a \emph{new} direction is very very small --- and we might be able to isolate this short piece by subtracting an appropriate combination of $\b_1$ and $\b_2$. 

To quantify this idea (that a vector is close to the space spanned by the previous vectors), we can use \emph{projections}.

\begin{defns}
	Suppose $\b_1,\ldots,\b_n$ is a basis for $\R^n$. For each $i$ from $1$ to $n$, let $S_i$ denote the \textbf{subspace spanned by the first $i$ vectors}:
	\[S_i=\{r_1\b_1+\ldots+r_i\b_i\mid r_1,\ldots,r_i\in\R\}.\]	
	Given any vector {\color{magenta}$\v\in\R^n$}, and any $i$, $\v$ can be decomposed in a unique way as
	\[{\color{magenta}\v}={\color{red}\text{Proj}_{S_i}(\v)}+{\color{blue}\text{Rem}_{S_i}(\v)},\]
	where {\color{red}$\text{Proj}_{S_i}(\v)$} (the {\color{red}\textbf{projection}} of $\v$ onto $S_i$) is contained in $S_i$, and {\color{blue}$\text{Rem}_{S_i}(\v)$} (the  {\color{blue}\textbf{remainder}} of the projection of $\v$ onto $S_i$) is orthogonal to every vector in  {\color{red}$S_i$}. 
	\begin{center}
		\begin{tikzpicture}
		\draw[fill=red!20]  (-1,2) -- (-4,-1) -- (4,-1) -- (7,2) -- cycle;
		
		\node at (-2,-0.5) {$S_2$};
		
		
		\node (v2) at (-1,1.5) {};
		\node (v3) at (5,4) {};
		\draw[-Latex] (0,0) -- (3, 0);
		\draw[-Latex]  (0,0) -- (v2);
		\draw[-Latex]  (0,0) -- (v3);
		\draw[dashed, -Latex,red] (0,0) -- (5,1) node[near end,sloped,above] {$\text{Proj}_{S_2}(\v)$};
		\draw[dashed, -Latex]  (5,1) -- (v3);
		\node at (3,-0.4) {$\b_1$};
		\node at (3,3) {\color{magenta}$\v$};
		\node at (-1,0.8) {$\b_2$};
		\node at (6.1,2.75) {\color{blue}$\text{Rem}_{S_2}(\v)$};
		\end{tikzpicture}
	\end{center}
	(We also set $S_0=\{\zero\}$, so $\text{Proj}_{S_0}(\v)=\zero$ and $\text{Rem}_{S_0}(\v)=\v$ for all $\v$.)
\end{defns}

The remainder function $\text{Rem}_{S_i}(\v)$ tells us what is \emph{new} about the vector $\v$; it describes what $\v$ is contributing to the world that hasn't already been done by vectors in $S_i$. Let
\[\b_k^*=\text{Rem}_{S_{k-1}}(\b_k)\]
denote the ``new contribution'' from $\b_k$ (the remainder after projecting onto all the previous basis vectors). The vectors $\b_k^*$ will usually \emph{not} be lattice vectors (except for $\b_1^*$), but they can be used to find a lower bound on the length of the shortest vector in a lattice! 

\begin{toprove}{Proposition}\label{prop:shortvbstar}
	Let a lattice $\LL$ be generated by $\{\b_1,\ldots,\b_n\}$. Then every nonzero vector in $\LL$ is longer than the minimum value of $\|\b_k^*\|$ over $k\in\{1,\ldots,n\}$.
\end{toprove}

\begin{explor}
	Given a lattice vector $\v=a_1\b_1+\cdots+a_n\b_n$, let $a_j$ be the last nonzero coefficient. What is the remainder after projecting $\v$ onto $S_{j-1}$? Use this to prove Proposition~\ref{prop:shortvbstar}.
\end{explor}

Go to [link] 

\begin{explor}
	Using the basis $\{\b_1,\b_2,\b_3\}$ from the start of this sheet, compute $\b_1^*$, $\b_2^*$, and $\b_3^*$. According to Proposition~\ref{prop:shortvbstar}, what is the shortest possible length of a nonzero lattice vector?
\end{explor}

Remember this definition?
\begin{defn}
	We will say that a $2$-dimensional basis $\{\u,\v\}$ is \textbf{reduced} if $\|\u\|\leq\|\v\|$ and $\|\v\|\leq\|\v+n\u\|$ for all integers $n$.
\end{defn}
For higher dimensions, instead of comparing pairs of basis vectors, we will will compare the \emph{new contributions} of basis vectors; that is, we will be comparing the \emph{remainders} of basis vectors after removing the projections onto all previous vectors. 
\begin{defn}
	An $n$-dimensional basis $\{\b_1,\ldots,\b_n\}$ is \textbf{LLL-reduced} {\color{DimGray}(with parameter $\delta=1$)} if the following are true for all $k=2,\ldots,n$:
	\begin{itemize}
		\item $\|\text{Rem}_{S_{k-2}}(\b_{k-1})\|\leq\|\text{Rem}_{S_{k-2}}(\b_k)\|$ (``$\b_k$ has \emph{larger remainder}''),\footnote{Careful: the first term is $\b_{k-1}^*$, but the second term is not $\b_k^*$. We're only projecting away the first $k-2$ vectors, not the first $k-1$.} and
		\item $\|\text{Rem}_{S_{i-1}}(\b_k)\|\leq\|\text{Rem}_{S_{i-1}}(\b_k)+n\text{Rem}_{S_{i-1}}(\b_i)\|$ for all $1\leq i< k$ and all $n\in\Z$ (``the pair $\{\b_i,\b_k\}$ is \emph{size-reduced}'').
	\end{itemize}
\end{defn}

\begin{explor}
	Is the basis $\b_1,\b_2,\b_3$ from the beginning of this sheet LLL-reduced? Why or why not?
\end{explor}

\begin{explor}
	If a basis $\b_1,\ldots,\b_n$ is LLL-reduced, prove that $\frac{\sqrt{3}}{2}\|\b_{k-1}^*\|\leq\|\b_k^*\|$. Use this to prove Proposition~\ref{prop:lllb1short}.
	
	\color{DarkGreen}(Hint: Plot $\text{Rem}_{S_{k-2}}(\b_{k-1})$ and $\text{Rem}_{S_{k-2}}(\b_k)$ in a $2$-D plane. Where is $\b_k^*$?)
\end{explor}

\begin{toprove}{Proposition}\label{prop:lllb1short}
	Suppose $\b_1,\ldots,\b_n$ is an LLL-reduced basis for a lattice $\LL$. If $\lambda_1$ denotes the length of the shortest nonzero vector of $\LL$, then $\|\b_1\|\leq \left(\frac{2}{\sqrt{3}}\right)^n\lambda_1$.
\end{toprove}

For example, in three dimensions, this tells us that that $\b_1$ will be no more than $1.54$ times the length of the shortest vector. So unlike the example we've been working with, LLL-reduced basis will not have any ``surprise'' vectors that are extremely short!

\section*{Finding an LLL-reduced basis}

The basic idea will be the same as in the $2$-D case. We have two operations:
\begin{itemize}
	\item ``Swap:'' If $\|\text{Rem}_{S_{k-2}}(\b_{k-1})\|>\|\text{Rem}_{S_{k-2}}(\b_k)\|$, swap $\b_{k-1}$ and $\b_k$.
	\item ``Size reduction:'' for $i<k$, add multiples of $\b_i$ to $\b_k$ until $\{\b_i,\b_k\}$ is size-reduced.
\end{itemize}
We can apply these operations to try and achieve the LLL-reduced conditions. It's not entirely clear, though, that repeating these operations over and over will eventually lead us to an LLL-reduced basis. Our attempts to fix one condition may break another!

\begin{explor}
	Suppose we start with the following basis:
	\[\u_1=\begin{pmatrix}
	1\\0\\0
	\end{pmatrix},\,\u_2=\begin{pmatrix}
	1/4\\1\\0
	\end{pmatrix},\,\u_3=\begin{pmatrix}
	0\\5\\1/2
	\end{pmatrix}.\]
	Show that $\{\u_1,\u_2\}$ and $\{\u_1,\u_3\}$ are size-reduced, but $\{\u_2,\u_3\}$ is not. Now size-reduce $\{\u_2,\u_3\}$ (that is, replace $\u_3$ with $\u_3+n\u_2$ for an appropriate integer $n$). Is $\{\u_1,\u_3\}$ still size-reduced?
\end{explor}

\begin{explor}
	Following up with the same example (using the new value of $\u_3$), now size-reduce $\{\u_1,\u_3\}$. Is $\{\u_2,\u_3\}$ still size-reduced?
\end{explor}

\begin{explor}
	Show that if you work \emph{backwards} --- that is, start by size-reducing $\{\b_{k-1},\b_k\}$, then $\{\b_{k-2},\b_k\}$, all the way down to $\{\b_1,\b_k\}$ --- then all pairs $\{\b_i,\b_k\}$ for $i<k$ will be size-reduced.
	
	\color{DarkGreen}(Hint: If $j<i$, and you add a multiple of $\b_j$ to $\b_k$, what is the effect on $\text{Rem}_{S_{i-1}}(\b_k)$?)
\end{explor}

\begin{explor}
	Continue applying the LLL operations to the basis $\{\u_1,\u_2,\u_3\}$ until you get an LLL-reduced basis.
\end{explor}

\begin{explor}
	Consider our original example $\{\b_1,\b_2,\b_3\}$. Does LLL reduction find the short vector?
\end{explor}

\begin{explor}[(Optional)]
	Apply LLL reduction to the basis from Day 2, Exploration~\ref{exp:polyroot}. What is a quadratic polynomial that $\alpha\approx 0.4708709$ may be a root of? \color{DarkGreen}(LLL reduction should involve $9$ swap steps in this case; doing a bit of extra coding to automate things may be helpful.)
\end{explor}

\section*{Optional Exploration: Polynomial-Time LLL}

We've defined an algorithm for LLL reduction. But does it actually work in practice? Unfortunately, the way we've described it, the algorithm will often be far too slow to be useful. A major breakthrough was to realize that including an ``approximation factor'' $\delta$ can drastically speed up the algorithm.

\begin{defn}
	An $n$-dimensional basis $\{\b_1,\ldots,\b_n\}$ is \textbf{LLL-reduced} with parameter $\delta\in (\frac14,1]$ if the following are true for all $k=2,\ldots,n$:
	\begin{itemize}
		\item (``Lov\'asz condition'') $\sqrt{\delta}\|\text{Rem}_{S_{k-2}}(\b_{k-1})\|\leq\|\text{Rem}_{S_{k-2}}(\b_k)\|$, and
		\item $\|\text{Rem}_{S_{i-1}}(\b_k)\|\leq\|\text{Rem}_{S_{i-1}}(\b_k)+n\text{Rem}_{S_{i-1}}(\b_i)\|$ for all $1\leq i< k$ and all $n\in\Z$.		
	\end{itemize}
\end{defn}

The LLL reduction algorithm is modified in a similar way; wherever we check to see if $\|\text{Rem}_{S_{k-2}}(\b_{k-1})\|\leq\|\text{Rem}_{S_{k-2}}(\b_k)\|$, we include the factor $\sqrt{\delta}$.

\begin{explor}
	Prove Proposition~\ref{prop:llldeltab1short}, which is a modification of Proposition~\ref{prop:lllb1short} to allow for the $\delta$ factor.
\end{explor}

\begin{toprove}{Proposition}\label{prop:llldeltab1short}
	Suppose $\b_1,\ldots,\b_n$ is an LLL-reduced basis (with parameter $\delta$) for a lattice $\LL$. If $\lambda_1$ denotes the length of the shortest nonzero vector of $\LL$, then $\|\b_1\|\leq \left(\delta-\frac14\right)^{-n/2}\lambda_1$.
\end{toprove}

We'll prove that if $\delta<1$, then the LLL algorithm can be run in polynomial time. 

\begin{defn}
	Given a basis $\b_1,\ldots,\b_n$, let $\LL_i$ denote the lattice generated by the first $i$ basis vectors:
	\[\LL_i=\left\{a_1\b_1+\cdots+a_i\b_i\mid a_1,\ldots,a_i\in\Z \right\}\]
\end{defn}




\begin{comment}

\begin{explor}
	To reduce $2$-D lattices, we needed to solve the following problem:
	\begin{itemize}
		\item Find $n$ such that $\v+n\u$ is as short as possible.
		\item Find $n$ such that the angle between $\u$ and $\v+n\u$ is as close to $90^\circ$ as possible.
	\end{itemize}
	Now suppose we try to solve a continuous version of this problem, with the integer $n$ replaced by any real number $r$. Describe the solution to this problem using $\text{Proj}$ and $\text{Rem}$.
\end{explor}




\begin{defn}
	Given vectors $\u=(u_1,\ldots,u_n)$ and $\v=(v_1,\ldots,v_n)$, their \textbf{dot product} is
	\[\u\cdot\v = u_1v_1+\cdots +u_nv_n.\]
	Note that $\u\cdot \u=\|\u\|^2$. The dot product is linear: $(\u+\v)\cdot \w=\u\cdot \w+\v\cdot \w$, and $(c\u)\cdot \v=c(\u\cdot \v)$ (and likewise for the second component).
\end{defn}


This gives us a way to automate $2$-D basis reduction even more; we can simply set $n$ to be the closest integer to $r$. Let's now generalize this result to higher dimensions. 

\begin{explor}
	Suppose the vectors $\u_1,\ldots,\u_k$ are all orthogonal to each other. The \textbf{projection of $\v$ onto the span of $\u_1,\ldots,\u_k$} is defined by
	\[\text{Proj}_{\{\u_1,\ldots,\u_k\}}(\v)=\frac{\v\cdot\u_1}{\u_1\cdot \u_1}\u_1+\cdots +\frac{\v\cdot\u_k}{\u_k\cdot \u_k}\u_k.\]
	Prove that $\v-\text{Proj}_{\{\u_1,\ldots,\u_k\}}(\v)$ is perpendicular to each of $\u_1,\ldots,\u_k$.
\end{explor}

It turns out that the right thing to do isn't to test whether each pair of basis vectors is reduced; it's to test whether each pair of basis vectors is reduced \emph{after removing the projections onto all the previous vectors.}

\begin{explor}
	Show that 
	\[\left\{\v_2-\text{Proj}_{\v_1}(\v_2),\,\v_3-\text{Proj}_{\v_1}(\v_3)\right\}\]
	is very much not a reduced basis.
\end{explor}

\section*{The LLL algorithm ($\delta=1$)}

A basis $\v_1,\ldots,\v_n$ is \textbf{LLL-reduced} if, for every pair of indices $1\leq i<j\leq n$, the pair of vectors 
\[\left\{\text{Proj}_{V_{i-1}^\perp}(\v_i),\,\text{Proj}_{V_{i-1}^\perp}(\v_j)\right\}\]
is reduced. 

Recall that the $2$-D reduction algorithm had two steps:

\begin{enumerate}
	\item (Size reduction) Replace $\v_2$ with $\v_2+n\v_1$, where $n$ is chosen so as to make $\v_2+n\v_1$ as short as possible.
	\item (Swap) If $\{\v_1,\v_2\}$ is not reduced, swap them and repeat.
\end{enumerate}

We will make some minor modifications


\begin{comment}

Given a basis $\v_1,\ldots,\v_n$, the \textbf{Gram-Schmidt basis}, $\widetilde{\v_1},\ldots,\widetilde{\v_n}$ is defined recursively by getting rid of the projections onto all previous vectors:
\[\widetilde{\v_1}=v_1,\qquad \widetilde{\v_{i+1}}=\v_{i+1}-\text{Proj}_{\{\widetilde{\v_1},\ldots,\widetilde{\v_i}\}}(\v_{i+1}).\]
Note that the Gram-Schmidt basis will \emph{not} typically generate the same lattice.

\begin{explor}
	Compute the Gram-Schmidt basis for our running example $\{\u,\v,\w\}$.
\end{explor}

\begin{explor}
	Suppose that $\x=a_1\v_1+\cdots a_n\v_n$ is a nonzero lattice vector. Suppose $a_j\neq 0$, but $a_k=0$ for all $k>j$. Prove that $\|\x\|\geq |a_j|\|\widetilde{\v_j}\|$. Use this to find a lower bound for the length of a shortest vector: $\lambda_1\geq \min_i\|\widetilde{\v_i}\|$.
\end{explor}

\begin{explor}
	The determinant of a matrix does not change if multiples of one column are added to another column. Use this to prove that the basis matrix for $\{\v_1,\ldots,\v_n\}$ and for $\{\widetilde{\v_1},\ldots,\widetilde{\v_n}\}$ have the same determinant. Conclude that the volume of the fundamental parallelepiped of $\LL$ equals the product $\|\widetilde{\v_1}\|\cdots\|\widetilde{\v_n}\|$.
\end{explor}

The previous two explorations, together with Corollary~\ref{cor:lengthbound} from yesterday, prove that
\[\min_i\|\widetilde{\v_i}\|\leq \lambda_1\leq \sqrt{n}\prod_{i=1}^n\|\widetilde{\v_1}\|.\]

\end{comment}
 