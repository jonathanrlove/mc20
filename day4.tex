\newsheet{Day 4: LLL Reduction}{3}{4}

\begin{displayquote}
	``Computational aspects of geometry of numbers have been revolutionized by the 	Lenstra-Lenstra-Lov\'asz lattice reduction algorithm (LLL), which has led to breakthroughs in fields as diverse as computer algebra, cryptology, and algorithmic number theory. After its publication in 1982, LLL was immediately recognized as one of the most important algorithmic achievements of the twentieth century, because of its broad applicability and apparent simplicity.''
\end{displayquote}
\begin{flushright}\small
	$\sim$ Phong Q. Nguyen and Brigitte Vall\'ee (2009)
\end{flushright}

We need a better notion of ``reduced'' bases. For instance, let's use our example from before:

\[\b_1=\begin{pmatrix}
1\\0\\-10^{-6}
\end{pmatrix},\,\b_2=\begin{pmatrix}
1/2 \\ \sqrt{3}/2 \\ 2\cdot 10^{-6}
\end{pmatrix},\,\b_3=\begin{pmatrix}
-1/2 \\ \sqrt{3}/2 \\ -3\cdot 10^{-6}
\end{pmatrix},\,\b_2-\b_1-\b_3=\begin{pmatrix}
0 \\ 0 \\ 6\cdot 10^{-6}
\end{pmatrix}.\]

How could we have predicted the existence of a short vector? One way (discussed yesterday) is Minkowski's Theorem. But another approach is to notice that $\b_3$ is \emph{extremely close} to the plane spanned by $\b_1$ and $\b_2$. In other words, the only contribution from $\b_3$ in a \emph{new} direction is very very small.

To quantify this idea (that a vector is close to the space spanned by the previous vectors), we can use \emph{projections}.

\begin{defns}
	Suppose $\b_1,\ldots,\b_n$ is a basis for $\R^n$. For each $i$ from $1$ to $n$, let $S_i$ denote the \textbf{subspace spanned by the first $i$ vectors}:
	\[S_i=\{r_1\b_1+\ldots+r_i\b_i\mid r_1,\ldots,r_i\in\R\}.\]	
	Given any vector {\color{magenta}$\v\in\R^n$}, and any $i$, it can be decomposed uniquely as
	\[{\color{magenta}\v}={\color{red}\text{Proj}_{S_i}(\v)}+{\color{blue}\text{Rem}_{S_i}(\v)},\]
	where {\color{red}$\text{Proj}_{S_i}(\v)$} (the {\color{red}\textbf{projection}} of $\v$ onto $S_i$) is contained in $S_i$, and {\color{blue}$\text{Rem}_{S_i}(\v)$} (the  {\color{blue}\textbf{remainder}} of the projection of $\v$ onto $S_i$) is orthogonal to every vector in  {\color{red}$S_i$}. 
	\begin{center}
		\begin{tikzpicture}
		\draw[fill=red!20]  (-1,2) -- (-4,-1) -- (4,-1) -- (7,2) -- cycle;
		
		\node at (-2,-0.5) {$S_2$};
		
		
		\node (v2) at (-1,1.5) {};
		\node (v3) at (5,4) {};
		\draw[-Latex] (0,0) -- (3, 0);
		\draw[-Latex]  (0,0) -- (v2);
		\draw[-Latex]  (0,0) -- (v3);
		\draw[dashed, -Latex,red] (0,0) -- (5,1) node[near end,sloped,above] {$\text{Proj}_{S_2}(\v)$};
		\draw[dashed, -Latex]  (5,1) -- (v3);
		\node at (3,-0.4) {$\b_1$};
		\node at (3,3) {\color{magenta}$\v$};
		\node at (-1,0.8) {$\b_2$};
		\node at (6.1,2.75) {\color{blue}$\text{Rem}_{S_2}(\v)$};
		\end{tikzpicture}
	\end{center}
	(We also set $S_0=\{\zero\}$, so $\text{Proj}_{S_0}(\v)=\zero$ and $\text{Rem}_{S_0}(\v)=\v$ for all $\v$.)
\end{defns}

The remainder function $\text{Rem}_{S_i}(\v)$ tells us what is \emph{new} about the vector $\v$; it describes what $\v$ is contributing to the world that hasn't already been done by vectors in $S_i$. Let
\[\b_k^*=\text{Rem}_{S_{k-1}}(\b_k)\]
denote the ``new contribution'' from $\b_k$ (the remainder after projecting onto all the previous basis vectors). The vectors $\b_k^*$ will usually \emph{not} be lattice vectors (except for $\b_1^*$), but they can be used to find a lower bound on the shortest vectors in a lattice! 

\begin{toprove}{Proposition}\label{prop:shortvbstar}
	Let a lattice $\LL$ be generated by $\{\b_1,\ldots,\b_n\}$. Then every vector in $\LL$ is longer than the minimum value of $\|\b_k^*\|$ over $k\in\{1,\ldots,n\}$.
\end{toprove}

\begin{explor}
	Given a lattice vector $a_1\b_1+\cdots+a_n\b_n$, let $a_j$ be the last nonzero coefficient. What is the remainder after projection onto $S_{j-1}$? Use this to prove Proposition~\ref{prop:shortvbstar}.
\end{explor}

Go to 

\begin{explor}
	Using the basis $\{\b_1,\b_2,\b_3\}$ from the start of this sheet, compute $\b_1^*$, $\b_2^*$, and $\b_3^*$.
\end{explor}

Remember this definition?
\begin{defn}
	We will say that a $2$-dimensional basis $\{\u,\v\}$ is \textbf{reduced} if $\|\u\|\leq\|\v\|$ and $\|\v\|\leq\|\v+n\u\|$ for all integers $n$.
\end{defn}
For higher dimensions, instead of comparing pairs of basis vectors, we will will compare the \emph{new contributions} of basis vectors; that is, we will be comparing the \emph{remainders} of basis vectors after removing the projections onto all previous vectors. 
\begin{defn}
	An $n$-dimensional basis $\{\b_1,\ldots,\b_n\}$ is \textbf{LLL-reduced} (with parameter $\delta=1$) if the following are true for all $k=2,\ldots,n$:
	\begin{itemize}
		\item $\|\text{Rem}_{S_{k-2}}(\b_{k-1})\|\leq\|\text{Rem}_{S_{k-2}}(\b_k)\|$, and
		\item For all $1\leq i\leq k$ and all integers $n$,  $\|\text{Rem}_{S_{i-1}}(\b_k)\|\leq\|\text{Rem}_{S_{i-1}}(\b_k)+n\text{Rem}_{S_{i-1}}(\b_i)\|$.
	\end{itemize}
\end{defn}

\begin{explor}
	Is the basis $\b_1,\b_2,\b_3$ from the beginning of this sheet LLL-reduced? Why or why not?
\end{explor}

\begin{explor}
	Suppose $\v$ is any vector in $\R^n$, and $\w$ is a vector contained in $S_i$. How are $\text{Rem}_{S_i}(\v)$ and $\text{Rem}_{S_i}(\v+\w)$ related?
	
	Now suppose that $\|\text{Rem}_{S_{i-1}}(\b_k)\|$ is smaller than $\|\text{Rem}_{S_{i-1}}(\b_k)+n\text{Rem}_{S_{i-1}}(\b_i)\|$ for all $n$. If you replace $\b_k$ with $\b_k+m\b_j$ for some $j<i$ and some integer $m$, show that this condition is still satisfied.
\end{explor}











\begin{explor}
	To reduce $2$-D lattices, we needed to solve the following problem:
	\begin{itemize}
		\item Find $n$ such that $\v+n\u$ is as short as possible.
		\item Find $n$ such that the angle between $\u$ and $\v+n\u$ is as close to $90^\circ$ as possible.
	\end{itemize}
	Now suppose we try to solve a continuous version of this problem, with the integer $n$ replaced by any real number $r$. Describe the solution to this problem using $\text{Proj}$ and $\text{Rem}$.
\end{explor}




\begin{reference}
	Given vectors $\u=(u_1,\ldots,u_n)$ and $\v=(v_1,\ldots,v_n)$, their \textbf{dot product} is
	\[\u\cdot\v = u_1v_1+\cdots +u_nv_n.\]
	Note that $\u\cdot \u=\|\u\|^2$. The dot product is linear: $(\u+\v)\cdot \w=\u\cdot \w+\v\cdot \w$, and $(c\u)\cdot \v=c(\u\cdot \v)$ (and likewise for the second component).
\end{reference}


This gives us a way to automate $2$-D basis reduction even more; we can simply set $n$ to be the closest integer to $r$. Let's now generalize this result to higher dimensions. 

\begin{explor}
	Suppose the vectors $\u_1,\ldots,\u_k$ are all orthogonal to each other. The \textbf{projection of $\v$ onto the span of $\u_1,\ldots,\u_k$} is defined by
	\[\text{Proj}_{\{\u_1,\ldots,\u_k\}}(\v)=\frac{\v\cdot\u_1}{\u_1\cdot \u_1}\u_1+\cdots +\frac{\v\cdot\u_k}{\u_k\cdot \u_k}\u_k.\]
	Prove that $\v-\text{Proj}_{\{\u_1,\ldots,\u_k\}}(\v)$ is perpendicular to each of $\u_1,\ldots,\u_k$.
\end{explor}

It turns out that the right thing to do isn't to test whether each pair of basis vectors is reduced; it's to test whether each pair of basis vectors is reduced \emph{after removing the projections onto all the previous vectors.}

\begin{explor}
	Show that 
	\[\left\{\v_2-\text{Proj}_{\v_1}(\v_2),\,\v_3-\text{Proj}_{\v_1}(\v_3)\right\}\]
	is very much not a reduced basis.
\end{explor}

\section*{The LLL algorithm ($\delta=1$)}

A basis $\v_1,\ldots,\v_n$ is \textbf{LLL-reduced} if, for every pair of indices $1\leq i<j\leq n$, the pair of vectors 
\[\left\{\text{Proj}_{V_{i-1}^\perp}(\v_i),\,\text{Proj}_{V_{i-1}^\perp}(\v_j)\right\}\]
is reduced. 

Recall that the $2$-D reduction algorithm had two steps:

\begin{enumerate}
	\item (Size reduction) Replace $\v_2$ with $\v_2+n\v_1$, where $n$ is chosen so as to make $\v_2+n\v_1$ as short as possible.
	\item (Swap) If $\{\v_1,\v_2\}$ is not reduced, swap them and repeat.
\end{enumerate}

We will make some minor modifications


\begin{comment}

Given a basis $\v_1,\ldots,\v_n$, the \textbf{Gram-Schmidt basis}, $\widetilde{\v_1},\ldots,\widetilde{\v_n}$ is defined recursively by getting rid of the projections onto all previous vectors:
\[\widetilde{\v_1}=v_1,\qquad \widetilde{\v_{i+1}}=\v_{i+1}-\text{Proj}_{\{\widetilde{\v_1},\ldots,\widetilde{\v_i}\}}(\v_{i+1}).\]
Note that the Gram-Schmidt basis will \emph{not} typically generate the same lattice.

\begin{explor}
	Compute the Gram-Schmidt basis for our running example $\{\u,\v,\w\}$.
\end{explor}

\begin{explor}
	Suppose that $\x=a_1\v_1+\cdots a_n\v_n$ is a nonzero lattice vector. Suppose $a_j\neq 0$, but $a_k=0$ for all $k>j$. Prove that $\|\x\|\geq |a_j|\|\widetilde{\v_j}\|$. Use this to find a lower bound for the length of a shortest vector: $\lambda_1\geq \min_i\|\widetilde{\v_i}\|$.
\end{explor}

\begin{explor}
	The determinant of a matrix does not change if multiples of one column are added to another column. Use this to prove that the basis matrix for $\{\v_1,\ldots,\v_n\}$ and for $\{\widetilde{\v_1},\ldots,\widetilde{\v_n}\}$ have the same determinant. Conclude that the volume of the fundamental parallelepiped of $\LL$ equals the product $\|\widetilde{\v_1}\|\cdots\|\widetilde{\v_n}\|$.
\end{explor}

The previous two explorations, together with Corollary~\ref{cor:lengthbound} from yesterday, prove that
\[\min_i\|\widetilde{\v_i}\|\leq \lambda_1\leq \sqrt{n}\prod_{i=1}^n\|\widetilde{\v_1}\|.\]

\end{comment}
 